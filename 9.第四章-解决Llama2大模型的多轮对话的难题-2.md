结合上下文理解多项约束条件，每次应答都与上下文有强关联关系。

- **连续性**：对话需要具备连续性，一旦捕捉到用户意图、确定了任务，就以完成此任务为目标，进行持续性的对话。

- **封闭域**：“某类特定问题”表明对话是受限的，即这是一个封闭域的问题。对话系统仅负责完成某个领域内已知的一系列任务，如订机票、订外卖或查天气等。

### 4.2 实操构造多轮对话微调训练数据集

假设我们手头有已经收集好的包含多次交流的对话数据（这里拿出一轮对话来进行微调训练数据集构造说明），在第n次交流中，User和Assistant的输入分别标记为(n)User、(n)Assistant。

(1) User: 你好。

(2) Assistant: 你好，需要我做什么？

(3) User: 今天天气如何？

(4) Assistant: 今天北京的天空晴朗，温度在35°C左右，紫外线强度高，请注意防晒。

(5) User: 多谢。

(6) Assistant: 不用谢。


在模型微调的指令调整阶段，通常只有(n)Assistant部分的loss值会被用于梯度传递以更新模型权重，而(n)User部分的loss值通常不会被用于模型权重更新。如何利用上面这段多次交流的数据来训练大模型呢？当前主要有三种方法，其中第一种、第二种是主流的方法，第三种是Firefly团队提出的方法。

- **方法一**：多轮对话中的最后一个Assistant部分的loss值参与模型权重更新，不产生重复计算。

(1)User、(2)Assistant、(3)User、(4)Assistant、(5)User作为模型的输入部分，(6)Assistant作为模型的Predict部分，只有(6)Assistant部分的loss值参与模型权重更新，如图4-1所示。这种方法的弊端在于，未充分利用多轮对话的训练数据，(2)Assistant和(4)Assistant两部分未参与模型训练，被浪费了。

在实操中，对于多轮对话训练数据而言，中间的Assistant部分的信息也很重要，最后一个Assistant部分往往是“谢谢”“不客气”等结束文本。如果只使用这部分文本训练模型，则会严重影响模型的训练效果。

采用Alpaca模型或Vicuna模型的数据组织风格，可以将多轮对话组织成如下格式（训练时需要在每个Assistant部分的回复后面都添加</s>，作为此轮对话生成结束的标识符，否则推理时模型很难采样到</s>，从而无法结束对话生成，关于<s></s>的用法会在4.3节中详细介绍）：

![image](https://github.com/user-attachments/assets/e7d0f62a-09bf-4e9b-9d28-a1ee519fb879)


```
<s>
Below is a conversation between a user and an assistant.
User: input1
Assistant: output1
User: input2
Assistant: output2
User: input3
Assistant: output3</s>...
```

在生成token_id时，还会生成一个output_mask，取值为0或1，用来标记各个token是否属于output部分，即是否需要模型进行预测。其中，“output</s>”部分的output_mask均为1，其他部分的output_mask均为0，如图4-2所示，其中第一行为token_id，第二行为output_mask。

![image](https://github.com/user-attachments/assets/aeb5c6ec-ebc8-40f1-99a7-24104204e554)


计算每个位置的loss值，只有output_mask=1位置的loss值才参与模型权重更新。

- **方法二**：多轮对话中的每个Assistant部分的loss值都参与模型权重更新，产生重复计算。

将一条多轮对话数据拆分成多条数据，如图4-3所示。

![image](https://github.com/user-attachments/assets/10e6920c-00e5-47db-80f9-17d1d2ae0857)


相比方法一，方法二能够更加充分地利用多轮对话中的每个Assistant部分的内容。其弊端在于，需要将一条包含n轮对话的数据拆分成n条数据，训练效率降低为1/n，成本也升高了很多。


采用Alpaca模型或Vicuna模型的数据组织风格，可以将多轮对话拆分成如下格式：

**数据1**：

```
Below is a conversation between a user and an assistant.
User: input1
Assistant: output1</s>
```

**数据2**：

```
Below is a conversation between a user and an assistant.
User: input1
Assistant: output1
User: input2
Assistant: output2</s>...
```

**数据3**：

```
Below is a conversation between a user and an assistant.
User: input1
Assistant: output1
User: input2
Assistant: output2
User: input3
Assistant: output3</s>...
```

这3条数据在生成token_id时，还会生成一个output_mask，取值为0或1，用来标记每条数据中各个token是否属于output部分，即是否需要模型进行预测。其中，“output</s>”部分的output_mask均为1，其他部分的output_mask均为0，如图4-4所示，其中每条数据中第一行为token_id，第二行为output_mask。 

![image](https://github.com/user-attachments/assets/11d7c495-22d2-4796-8ca8-dca996367dd1)


- **方法三**：将多轮对话数据拼接之后输入模型。

Firefly团队提出了一种更加充分且高效的方法，如图4-5所示，将多轮对话数据拼接之后输入模型，并行计算每个位置的loss值，只有Assistant部分的loss值参与模型权重更新。

![image](https://github.com/user-attachments/assets/1214d057-83de-4b25-8f93-f0d7e96d75ea)


采用Alpaca模型或Vicuna模型的数据组织风格，可以将多轮对话拆分成如下格式：

```
Below is a conversation between a user and an assistant.
User: input1
Assistant: output1</s>
User: input2
Assistant: output2</s>
User: input3
Assistant: output3</s>...
```

在生成token_id时，还会生成一个output_mask，取值为0或1，用来标记各个token是否属于output部分，即是否需要模型进行预测。其中，“output</s>”部分的output_mask均为1，其他部分的output_mask均为0，如图4-6所示，其中第一行为token_id，第二行为output_mask。

![image](https://github.com/user-attachments/assets/27a6ea32-8792-4fbe-b6f6-fd9ae0daad14)


计算每个位置的loss值，只有output_mask=1位置的loss值才参与模型权重更新。这种方法充分利用了模型并行计算的优势，更加高效，并且多轮对话中的每个target部分都参与了模型训练，更加充分地利用了数据。
loss值计算的实现方式可参考以下代码：

```python
class TargetLMLoss(Loss):
    def __init__(self, ignore_index):
        super().__init__()
        self.ignore_index = ignore_index
        self.loss_fn = nn.CrossEntropyLoss(ignore_index=ignore_index)
    def __call__(self, model, inputs, training_args, return_outputs=False):
        input_ids = inputs['input_ids']
        attention_mask = inputs['attention_mask']
        target_mask = inputs['target_mask']
        outputs = model(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)  # 模型前馈预测
        logits = outputs["logits"] if isinstance(outputs, dict) else outputs[0]
        # 将labels中不属于target的部分设为ignore_index，只计算target部分的loss值
        labels = torch.where(target_mask == 1, input_ids, self.ignore_index)
        shift_logits = logits[..., :-1, :].contiguous()
        shift_labels = labels[..., 1:].contiguous()
        loss = self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
        return (loss, outputs) if return_outputs else loss
```

### 4.3 通过多轮对话存储解决信息流失问题

在大模型（如GPT、BERT、Llama 2等）的微调、推理过程中，经常会遇到多轮对话存储问题，大模型在处理多轮对话时如何对其进行存储以解决信息流失问题是一个难题，处理不好会面临信息流失的问题从而影响大模型的表现，本节将介绍几种通过多轮对话存储解决信息流失问题的方法。

### 4.3.1 拼接历史与当前输入

在微调多轮对话数据集时，如何有效地管理和利用多轮对话历史是一个重要的问题。有一种广泛使用的方法是拼接历史与当前输入，即将之前几轮的对话内容拼接到当前轮的输入中。在实操中，LangChain的框架里有对应memory的模块，方便构建具有上下文记忆的多轮对话。这种方法在某些方面表现得相当出色，但也存在一些明显的局限性。

拼接历史与当前输入的方法相对直接和简单。当用户与系统进行交互时，每一轮的对话内容都会被存储。在下一轮对话开始时，系统将之前的历史信息与新的输入信息拼接在一起，形成一个更长的输入序列，类似于4.2节中的方法二。

拼接历史与当前输入方法的实施步骤如下。

- **历史记录**：保存每一轮的对话。

- **信息拼接**：在新一轮对话开始时，将保存的历史信息与当前输入信息拼接在一起。

- **模型输入**：将拼接后的信息输入模型。

**优点**

- **完整性**：通过这种方法，模型可以看到完整的对话历史，从而更好地理
  
