识；第二个阶段扩大低资源语言训练语料的占比，增强模型的多语言能力。文献[67]、[69]分别针对BigTranslate和PolyLM设计了不同的课程学习方法，感兴趣的读者可以深入了解。

- **基于Llama 2的多语言指令微调**：通常，如果我们并没有足够的GPU和语料资源进行多语言大模型的预训练，但仍希望Llama 2能在不同语言的任务中有比较好的效果，那么可以选择多语言指令微调，其模型结构和训练目标在前文进行了介绍。关于BLOOMZ[18]的研究发现，仅使用英语任务对BLOOM进行微调，得到的模型BLOOMZ-P3可以获得比原有模型（BLOOM）更好的效果；如果使用多语言的任务和英语指令对BLOOM进行微调，那么BLOOMZ能得到比原来更好的效果。鉴于我们采用的Llama 2是以英语为主的，所以建议使用后者来进行模型微调，以最小的成本提升Llama 2在多语言任务中的表现。

零样本多语言任务效果图（指令均为英语指令）如图7 - 19所示。

### 图7 - 19 零样本多语言任务效果图（指令均为英语指令）


|任务|模型|  |  |  |  |
| ---- | ---- | ---- | ---- | ---- | ---- |
|  | XGLM - 7.5B | BLOOMZ - P3 | BLOOM | BLOOMZ | mT0 - instruct - 1.3B |
|Sentence Completion (XCOPA & XStoryCloze)|51.8|80.5|82.6|86.0|50.4|
|Natural Language Inference (XNLI)|33.3|47.4|33.6|55.3|34.6|
|Coreference Resolution (XWinograd)|50.3|74.6|50.6|54.7|54.6|

![image](https://github.com/user-attachments/assets/89ad83cc-692d-42e6-bb55-2f447654245f)


在构造指令微调的数据集时，建议使用更高质量的数据进行微调，因为由Meta发表的LIMA论文[72]可知，微调数据的质量要比数量更重要。



### 7.4 多语言大模型的工业应用
大模型，即生成式AI的出现，让人们能以自然语言为指令与机器进行交互，同时借助各类API和操作获得想要的答案，它的出现正在重塑很多产业和工业应用。本节将重点介绍几个需要利用多语言大模型进行交互的典型工业应用，这些工业应用借助多语言大模型来提升相关领域的用户体验，以及提高运营效率。 

### 7.4 多语言大模型的工业应用
大模型，即生成式AI的出现，让人们能以自然语言为指令与机器进行交互，同时借助各类API和操作获得想要的答案，它的出现正在重塑很多产业和工业应用。本节将重点介绍几个需要利用多语言大模型进行交互的典型工业应用，这些工业应用借助多语言大模型来提升相关领域的用户体验，以及提高运营效率。

#### 7.4.1 智能客服
多语言大模型最为典型的一个工业应用就是智能客服。智能客服具有多轮对话能力，可以更自然地对用户提出的售前与售后问题进行回答，提高企业服务效率。同时，智能客服还可以识别用户的感情，针对不同用户进行安抚或情况上报，提升用户满意度并降低各类公关风险。

针对售前问题，智能客服更类似于导购机器人，会根据用户的诉求进行各种反问以收集信息，最后为用户推荐其可能感兴趣的产品以提高用户转化率。近期东南亚的电子商务平台Lazada与Shopify分别基于OpenAI的ChatGPT推出了自己的LazzieChat机器人和Shopify机器人。LazzieChat机器人主要支持英语和印尼语，而Shopify机器人支持汉语及更多的欧洲语言。

![image](https://github.com/user-attachments/assets/54f1e668-0459-45ca-8fee-919d44f0e3a9)


针对售后常见问题的解答，因为涉及专业领域知识，如不同平台的政策不一致，并且知识的实效性较高，所以一般会采用检索增强（RAG）的方法，既能利用外部的新知识，又能在一定程度上解决大模型的幻觉问题。一般会先针对领域知识构建向量数据库，再根据用户的问题从向量数据库中检索出相关的文档，然后将问题和文档及对应的提示交给大模型，让大模型完成答案的生成，并回复用户，整个过程和之前的阅读理解和文档问答任务非常相似。

![image](https://github.com/user-attachments/assets/b2080126-c245-4dad-ad92-20f2e6c7a34f)


除了简单的文档问答，有时智能客服还需要进行多轮任务型对话，也就是Taskbot。在这类任务中，大模型不仅需要具有多轮对话能力，还需要具有工具使用（如API调用）能力，以查询任务所需的槽位信息，而答案也会根据查询到的槽位信息而动态变化。现阶段这方面的研究主要集中在利用大模型将用户的指令转换为机器可以理解的动作或代码，随后在特定的环境中执行，即LLM-AGENT。项目开发的LLM-AGENT充当着自然语言与特定指令（API调用或动作序列，如配置好的对话流程）之间的桥梁，通过与环境及人类的一轮轮交流，大模型可以收集足够的上下文信息，从而精准、有效地完成任务，延伸并拓展用户意图。

#### 7.4.2 搜索引擎
除智能客服外，Google和微软的Bing等厂商也在利用RAG技术及多语言大模型提供网页搜索服务。使用了大模型的搜索引擎可以为用户提供更简洁的回复，当然代价就是可能会出现不准确的答案。Bing Chat系统演示图中，为了防止不准确的信息误导用户，它还标注了不同回复的出处，以帮助用户更好地寻找答案。

![image](https://github.com/user-attachments/assets/8be8608d-1273-481f-b611-841722d80946)


#### 7.4.3 机器翻译
机器翻译是一个天然的需要使用多语言大模型的场景，现阶段多语言大模型的翻译效果和原有的机器翻译模型在高资源语言下已经基本一致，虽然多语言大模型和Google的翻译效果在低资源语言上还有着不小的差距，但是已经可以基本满足对常见语句的翻译需求。同时，因为多语言大模型可以更好地理解上下文，所以其对一些会议和商业文件的翻译可能会有更好的效果。现阶段比较成熟的应用有Meta AI的SeamlessM4T ，以及中国科学院自动化研究所以Llama为基础训练的多语言大模型BigTranslate。 


![image](https://github.com/user-attachments/assets/f52d0a1f-20c5-43ca-9bb5-774ef7a4c815)
